{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# делаем посев случайных чисел предсказуемым\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция сигмоида - это математическая функция, имеющая форму буквы \"S\", которая определяется следующей формулой: \n",
    "\n",
    "\\begin{equation*}\n",
    "g(z)=\\frac{1}{1+e^{-z}}\n",
    "\\end{equation*}\n",
    "\n",
    "Данную функцию используют в нейронных сетях в качестве [функции активации](https://en.wikipedia.org/wiki/Activation_function). Ниже представлен график функции сигмоида."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# функция сигмоида\n",
    "def sigmoid(z):\n",
    "    a = 1/(1 + np.exp(-z))\n",
    "    return a\n",
    "\n",
    "t = np.arange(-10., 10., 0.1)\n",
    "\n",
    "plt.plot(sigmoid(t))\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве примера рассмотрим нейронную сеть, у которой один входной слой, один скрытый слой и один выходной слой. Входной слой состоит из вектора $\\vec{\\mathbf{x}}=[x_1, x_2, x_3]$, скрытый слой состоит из нейронов $[h_1, h_2, h_3, h_4]$, а выходной слой из одного нейрона $\\hat{y}$.<br><br>\n",
    "\n",
    "Далее, в качестве примера, определим данные для обучения нейронной сети. На вход нейронной сети будет подаваться обучающая выборка, которая является матрицей $\\text{x_train}$ размерности $\\text{[nrow x ncol]}$. Допустимые ответы определяются вектором $\\text{y_train}$. Для нейронной сети инициализируются матрицы весов скрытого слоя $w_1$ и выходного слоя $w_2$, а также вектора отклоней скрытого слоя $b_1$ и выходного слоя $b_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество элементов вектора x\n",
    "ncol = 3\n",
    "# обучающая выборка будет состоять из nrow элементов\n",
    "nrow = 5\n",
    "# количество нейронов в скрытом слое сети\n",
    "n_hidden_layer = 4\n",
    "# количество нейронов в выходном слое сети\n",
    "n_output = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка x_train:\n",
      "[[ 0.92961609  0.31637555  0.18391881]\n",
      " [ 0.20456028  0.56772503  0.5955447 ]\n",
      " [ 0.96451452  0.6531771   0.74890664]\n",
      " [ 0.65356987  0.74771481  0.96130674]\n",
      " [ 0.0083883   0.10644438  0.29870371]]\n",
      "\n",
      "Допустимые ответы y_train:\n",
      "[1 0 1 1 1]\n",
      "\n",
      "Матрица весов скрытого слоя w1:\n",
      "[[ 0.65641118  0.80981255  0.87217591]\n",
      " [ 0.9646476   0.72368535  0.64247533]\n",
      " [ 0.71745362  0.46759901  0.32558468]\n",
      " [ 0.43964461  0.72968908  0.99401459]]\n",
      "\n",
      "Отклонения скрытого слоя b1:\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "\n",
      "Матрица весов выходного слоя w2:\n",
      "[[ 0.67687371  0.79082252  0.17091426  0.02684928]]\n",
      "\n",
      "Отклонения выходного слоя b2:\n",
      "[[ 0.]]\n"
     ]
    }
   ],
   "source": [
    "# обучающая матрица, состоящая из nrow строк и ncol столбцов, элементы матрицы - случайные числа\n",
    "x_train = (np.random.random((nrow, ncol)))\n",
    "\n",
    "# результат\n",
    "y_train = np.array([1, 0, 1, 1, 1])\n",
    "\n",
    "# веса скрытоко слоя сети\n",
    "w1 = np.random.random((n_hidden_layer, ncol))\n",
    "\n",
    "# отклонения скрытого слоя сети\n",
    "#b1 = np.random.random((n_hidden_layer, 1))\n",
    "b1 = np.zeros((n_hidden_layer, n_output))\n",
    "\n",
    "# веса выходного слоя сети\n",
    "w2 = np.random.random((n_output, n_hidden_layer))\n",
    "\n",
    "# отклонения выходного слоя сети\n",
    "b2 = np.zeros((n_output, n_output))\n",
    "\n",
    "print(\"Обучающая выборка x_train:\")\n",
    "print(x_train)\n",
    "print(\"\\nДопустимые ответы y_train:\")\n",
    "print(y_train)\n",
    "print(\"\\nМатрица весов скрытого слоя w1:\")\n",
    "print(w1)\n",
    "print(\"\\nОтклонения скрытого слоя b1:\")\n",
    "print(b1)\n",
    "print(\"\\nМатрица весов выходного слоя w2:\")\n",
    "print(w2)\n",
    "print(\"\\nОтклонения выходного слоя b2:\")\n",
    "print(b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опредилив обучающий данные и инициализировав переменные нейронные сети можно начинать ее обучение. Выполним один шаг прямого распространения для нашей нейронной сети. Для этого необходимо выполнить расчет по следующим уравнениям:<br><br>\n",
    "\n",
    "\\begin{equation*}\n",
    "z_1=w_1 x_{train}^T+b_1\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "a_1=g(z_1)\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "z_2=w_2 a_1+b_2 \n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{y}=g(z_2)\n",
    "\\end{equation*}\n",
    "<br><br>\n",
    "Здесь функция активации $\\sigma$ является функцией сигмоида $g(z)$, определенного выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скрытый слой:\n",
      "[[ 1.02682485  1.11344625  1.81524746  1.87294799  0.35222835]\n",
      " [ 1.24387158  0.99080564  1.88426535  1.78919072  0.27703375]\n",
      " [ 0.87477447  0.6061304   1.24125192  1.13152352  0.15304485]\n",
      " [ 0.82237447  1.0961767   1.64508392  1.78849072  0.37827502]]\n",
      "\n",
      "Активация скрытого слоя:\n",
      "[[ 0.73629986  0.75277104  0.85999488  0.86679902  0.58715784]\n",
      " [ 0.7762372   0.72924702  0.86810029  0.85682803  0.56881886]\n",
      " [ 0.70573819  0.64705759  0.77578185  0.75611995  0.53818671]\n",
      " [ 0.69474014  0.74954305  0.83822552  0.85674213  0.59345699]]\n",
      "\n",
      "Выходной слой:\n",
      "[[ 1.25152187  1.21695195  1.42371911  1.41654695  0.95518414]]\n",
      "\n",
      "Активация выходного слоя:\n",
      "[[ 0.77756319  0.7715267   0.80592079  0.80479652  0.72215656]]\n"
     ]
    }
   ],
   "source": [
    "# Прямое распространение\n",
    "print(\"Скрытый слой:\")\n",
    "z1 = np.dot(w1, x_train.T) + b1\n",
    "print(z1)\n",
    "print(\"\\nАктивация скрытого слоя:\")\n",
    "a1 = sigmoid(z1)\n",
    "print(a1)\n",
    "print(\"\\nВыходной слой:\")\n",
    "z2 = np.dot(w2, a1) + b2\n",
    "print(z2)\n",
    "print(\"\\nАктивация выходного слоя:\")\n",
    "y_hat = a2 = sigmoid(z2)\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда получен первый результат работы нейронной сети, можно выполнить расчет значения функции ошибки для результата работы нейронной сети $\\hat{y}$ и допустимых ответов $\\text{y_train}$. Определим в качестве функции затрат функцию логистической потери (или потери перекрестной энтропии) следующего вида:<br>\n",
    "\\begin{equation*}\n",
    "Cost=-\\frac{1}{n}\\sum_{i=1}^nL_i=-\\frac{1}{n}\\sum_{i=1}^n\\left(y_ilog(\\hat{y_i})+(1-y_i)log(1-\\hat{y_i})\\right)\n",
    "\\end{equation*}\n",
    "Далее выполним расчет значения функции затрат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение функции затрат:\n",
      "[ 0.49727505]\n"
     ]
    }
   ],
   "source": [
    "# функция затрат\n",
    "cost = (1./nrow) * (-np.dot(y_train, np.log(y_hat).T) - np.dot(1 - y_train, np.log(1 - y_hat).T))\n",
    "print(\"Значение функции затрат:\")\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Для минимизации функции затрат методом [градиентного спуска](https://en.wikipedia.org/wiki/Gradient_descent) необходимо выполнить расчет следующих производных функций.\n",
    "<br><br>\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial{L}}{\\partial{w_2}}=\\frac{\\partial{L}}{\\partial{\\hat{y}}}\\frac{\\partial{\\hat{y}}}{\\partial{z_2}}\\frac{\\partial{z_2}}{\\partial{w_2}}\n",
    "\\end{equation*}<br>\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial{L}}{\\partial{b_2}}=\\frac{\\partial{L}}{\\partial{\\hat{y}}}\\frac{\\partial{\\hat{y}}}{\\partial{z_2}}\\frac{\\partial{z_2}}{\\partial{b_2}}\n",
    "\\end{equation*}<br>\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial{L}}{\\partial{w_1}}=\\frac{\\partial{L}}{\\partial{\\hat{y}}}\\frac{\\partial{\\hat{y}}}{\\partial{z_2}}\\frac{\\partial{z_2}}{\\partial{a_1}}\\frac{\\partial{a_1}}{\\partial{z_1}}\\frac{\\partial{z_1}}{\\partial{w_1}}\n",
    "\\end{equation*}<br>\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial{L}}{\\partial{b_1}}=\\frac{\\partial{L}}{\\partial{\\hat{y}}}\\frac{\\partial{\\hat{y}}}{\\partial{z_2}}\\frac{\\partial{z_2}}{\\partial{a_1}}\\frac{\\partial{a_1}}{\\partial{z_1}}\\frac{\\partial{z_1}}{\\partial{b_1}}\n",
    "\\end{equation*}<br>\n",
    "\n",
    "Для решения этих уравнений определим следующие производный функций:<br><br>\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial{L}}{\\partial{\\hat{y}}}=-\\left(\\frac{y}{\\hat{y}}-\\frac{1-y}{1-\\hat{y}}\\right )=\\frac{\\hat{y}-y}{\\hat{y}*(1-y)}\n",
    "\\end{equation*}<br>\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial{\\hat{y}}}{\\partial{z_2}}=\\frac{\\partial{g(z_2)}}{\\partial{z_2}}=\\frac{1}{1+e^{-z_2}}*\\left(1-\\frac{1}{1+e^{-z_2}}\\right )=g(z_2)*\\left(1-g(z_2)\\right)=\\hat{y}*\\left(1-\\hat{y}\\right)\n",
    "\\end{equation*}<br>\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial{z_2}}{\\partial{w_2}}=\\frac{\\partial{\\left(w_2 a_1+b_2\\right)}}{\\partial{w_2}}=a_1\n",
    "\\end{equation*}<br>\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial{z_2}}{\\partial{b_2}}=\\frac{\\partial{\\left(w_2 a_1+b_2\\right)}}{\\partial{b_2}}=1\n",
    "\\end{equation*}<br>\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial{z_2}}{\\partial{a_1}}=\\frac{\\partial{\\left(w_2 a_1+b_2\\right)}}{\\partial{a_1}}=w_2\n",
    "\\end{equation*}<br>\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial{a_1}}{\\partial{z_1}}=\\frac{\\partial{\\sigma{(z_1)}}}{\\partial{z_1}}=\\frac{1}{1+e^{-z_1}}*\\left(1-\\frac{1}{1+e^{-z_1}}\\right )=\\sigma{(z_1)}*(1-\\sigma{(z_1)})=a_1*\\left(1-a_1\\right)\n",
    "\\end{equation*}<br>\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial{z_1}}{\\partial{w_1}}=\\frac{\\partial{\\left(w_1x_{train}^T+b_1\\right)}}{\\partial{w_1}}=x_{train}^T\n",
    "\\end{equation*}<br>\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial{z_1}}{\\partial{b_1}}=\\frac{\\partial{\\left(w_1x_{train}^T+b_1\\right)}}{\\partial{b_1}}=1\n",
    "\\end{equation*}<br>\n",
    "\\begin{equation*}\n",
    "dz_2=\\frac{\\partial{L}}{\\partial{\\hat{y}}}\\frac{\\partial{\\hat{y}}}{\\partial{z_2}}=\\frac{\\hat{y}-y}{\\hat{y}(1-y)}*\\hat{y}\\left(1-\\hat{y}\\right)=\\hat{y}-y\n",
    "\\end{equation*}<br>\n",
    "\\begin{equation*}\n",
    "dz_1=\\frac{\\partial{L}}{\\partial{\\hat{y}}}\\frac{\\partial{\\hat{y}}}{\\partial{z_2}}\\frac{\\partial{z_2}}{\\partial{a_1}}\\frac{\\partial{a_1}}{\\partial{z_1}}=\\left(dz_2w_2^T\\right)*\\left(a_1*\\left(1-a_1\\right)\\right)\n",
    "\\end{equation*}\n",
    "\n",
    "<br><br>\n",
    "Отсюда:\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial{Cost}}{\\partial{w_2}}=\\frac{1}{n}\\left(dz_2a_1^T\\right)\n",
    "\\end{equation*}<br>\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial{Cost}}{\\partial{b_2}}=\\frac{1}{n}\\sum_{i=1}^n\\left(dz_{2i}\\right)\n",
    "\\end{equation*}<br>\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial{Cost}}{\\partial{w_1}}=\\frac{1}{n}\\left(dz_1x_{train}\\right)\n",
    "\\end{equation*}<br>\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial{L}}{\\partial{b_1}}=\\frac{1}{n}\\sum_{i=1}^n\\left(dz_{1i}\\right)\n",
    "\\end{equation*}<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Производная функции стоимости:\n",
      "[[-1.28606911  4.37687914 -1.24081673 -1.24255011 -1.38474129]]\n"
     ]
    }
   ],
   "source": [
    "# обратное распространение\n",
    "# произодная функции стоимости\n",
    "cost_derivative = - (np.divide(y_train, y_hat) - np.divide(1 - y_train, 1 - y_hat))\n",
    "print(\"Производная функции стоимости:\")\n",
    "print(cost_derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.25152187  1.21695195  1.42371911  1.41654695  0.95518414]]\n"
     ]
    }
   ],
   "source": [
    "dz2 = cost_derivative * y_hat * (1 - y_hat)\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d(Cost)/d(w2):\n",
      "[[-0.0164489  -0.02076176 -0.02109039 -0.01421053]]\n",
      "d(Cost)/d(b2):\n",
      "[[-0.02360725]]\n"
     ]
    }
   ],
   "source": [
    "dw2 = (1./nrow) * np.dot(dz2, a1.T)\n",
    "db2 = (1./nrow) * np.sum(dz2, axis=1, keepdims=True)\n",
    "da1 = np.dot(w2.T,dz2)\n",
    "print(\"d(Cost)/d(w2):\")\n",
    "print(dw2)\n",
    "print(\"d(Cost)/d(b2):\")\n",
    "print(db2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d(Cost)/d(w1):\n",
      "[[ -6.58065662e-03   3.86756931e-03   2.47531655e-03]\n",
      " [ -6.70789919e-03   5.47042307e-03   3.73248917e-03]\n",
      " [ -2.17286412e-03   9.94745525e-04   5.44339470e-04]\n",
      " [ -2.99798942e-04   1.34588181e-04   7.95641160e-05]]\n",
      "d(Cost)/d(b1):\n",
      "[[ -1.74071177e-03]\n",
      " [ -9.72444693e-05]\n",
      " [ -3.01078239e-04]\n",
      " [ -1.05498568e-04]]\n"
     ]
    }
   ],
   "source": [
    "dz1 = da1 * a1 * (1 - a1)\n",
    "\n",
    "dw1 = (1./nrow) * np.dot(dz1, x_train)\n",
    "db1 = (1./nrow) * np.sum(dz1, axis=1, keepdims=True)\n",
    "da0 = np.dot(w1.T,z1)\n",
    "\n",
    "print(\"d(Cost)/d(w1):\")\n",
    "print(dw1)\n",
    "print(\"d(Cost)/d(b1):\")\n",
    "print(db1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий шаг в обучении нашей нейронное сети - это обновление матриц весов $w_2$, $w_1$ и векторов отклонений $b_2$, $b_1$ в соответствии с коэффициентом обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определим коэффициент обучения\n",
    "learning_rate = 0.5\n",
    "\n",
    "# обновляем значения весов\n",
    "w1_step1 = w1 - learning_rate * dw1\n",
    "b1_step1 = b1 - learning_rate * db1\n",
    "w2_step1 = w2 - learning_rate * dw2\n",
    "b2_step1 = b2 - learning_rate * db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скрытый слой [Шаг1]:\n",
      "[[ 1.02991452  1.11315474  1.81710139  1.87333312  0.35255077]\n",
      " [ 1.2458295   0.98887607  1.88436468  1.78759219  0.27626191]\n",
      " [ 0.87572756  0.60605872  1.24192164  1.13175058  0.15307026]\n",
      " [ 0.82253796  1.09619822  1.64520751  1.78855288  0.37830998]]\n",
      "\n",
      "Активация скрытого слоя [Шаг1]:\n",
      "[[ 0.73689932  0.75271679  0.86021795  0.86684348  0.587236  ]\n",
      " [ 0.77657709  0.72886587  0.86811166  0.85663182  0.56862954]\n",
      " [ 0.70593609  0.64704122  0.77589833  0.75616182  0.53819302]\n",
      " [ 0.69477481  0.74954709  0.83824228  0.85674976  0.59346543]]\n",
      "\n",
      "Выходной слой [Шаг1]:\n",
      "[[ 1.25152187  1.21695195  1.42371911  1.41654695  0.95518414]]\n",
      "\n",
      "Активация выходного слоя [Шаг1]:\n",
      "[[ 0.78411632  0.77810652  0.81240962  0.81129319  0.72861631]]\n"
     ]
    }
   ],
   "source": [
    "# Прямое распространение\n",
    "print(\"Скрытый слой [Шаг1]:\")\n",
    "z1_step1 = np.dot(w1_step1, x_train.T) + b1_step1\n",
    "print(z1_step1)\n",
    "print(\"\\nАктивация скрытого слоя [Шаг1]:\")\n",
    "a1_step1 = sigmoid(z1_step1)\n",
    "print(a1_step1)\n",
    "print(\"\\nВыходной слой [Шаг1]:\")\n",
    "z2_step1 = np.dot(w2_step1, a1) + b2_step1\n",
    "print(z2)\n",
    "print(\"\\nАктивация выходного слоя [Шаг1]:\")\n",
    "y_hat_step1 = a2_step1 = sigmoid(z2_step1)\n",
    "print(y_hat_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение функции затрат [Шаг1]:\n",
      "[ 0.49644802]\n"
     ]
    }
   ],
   "source": [
    "# функция затрат\n",
    "cost_step1 = (1./nrow) * (-np.dot(y_train, np.log(y_hat_step1).T) - np.dot(1 - y_train, np.log(1 - y_hat_step1).T))\n",
    "print(\"Значение функции затрат [Шаг1]:\")\n",
    "print(cost_step1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уменьшение значения функции затрат:\n",
      "[ 0.00082703]\n"
     ]
    }
   ],
   "source": [
    "print(\"Уменьшение значения функции затрат:\")\n",
    "print(cost - cost_step1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В следующем примере будет полностью реализован градиентный спуск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
